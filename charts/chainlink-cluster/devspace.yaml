version: v2beta1
name: chainlink

vars:
  DEVSPACE_ENV_FILE: .env

# This is a list of `pipelines` that DevSpace can execute (you can define your own)
pipelines:
  dev:
    # We don't need a rollout here and image haven't been really changed,
    # may not deserve to be commited, so we are just rebooting the app pods
    run: |-
      devspace run-pipeline deploy
      kubectl get pods -n ${DEVSPACE_NAMESPACE} --no-headers=true | grep '^app-node-' | awk '{print $1}' | xargs kubectl delete pod -n ${DEVSPACE_NAMESPACE}
      kubectl wait pods -n ${DEVSPACE_NAMESPACE} --selector=app=app --for=condition=Ready --timeout=${DEVSPACE_K8S_POD_WAIT_TIMEOUT}
  # You can run this pipeline via `devspace deploy` (or `devspace run-pipeline deploy`)
  deploy:
    run: |-
      run_dependencies --all
      ensure_pull_secrets --all
      build_images --all
      
      kubectl label namespace ${DEVSPACE_NAMESPACE} cleanup.kyverno.io/ttl=${NS_TTL} || true
      kubectl label namespace/${DEVSPACE_NAMESPACE} network=crib || true

      create_deployments app 
      echo
      echo "Namespace ${DEVSPACE_NAMESPACE} will be deleted in ${NS_TTL}"
      echo "To extend the TTL for e.g. 72 hours, run: devspace run ttl ${DEVSPACE_NAMESPACE} 72h"

      echo
      echo "############################################"
      echo "Ingress Domains"
      echo "############################################"
      ingress_names="node1 node2 node3 node4 node5 node6 geth-1337-http geth-1337-ws geth-2337-http geth-2337-ws"
      for ingress in ${ingress_names}; do
        echo "https://${DEVSPACE_NAMESPACE}-${ingress}.${DEVSPACE_INGRESS_BASE_DOMAIN}"
      done

  purge:
    run: |-
      kubectl delete ns ${DEVSPACE_NAMESPACE}

commands:
  connect: |-
    sudo kubefwd svc -n $1
  ttl: |-
    kubectl label namespace $1 cleanup.kyverno.io/ttl=$2 --overwrite

images:
  app:
    image: ${DEVSPACE_IMAGE}
    tags:
      - ${devspace.namespace}-${devspace.timestamp}
    custom:
      skipImageArg: true
      command: |-
        GIT_ROOT=$(git rev-parse --show-toplevel)
        cd $GIT_ROOT

        image=${runtime.images.app}
        MACOS_SDK_DIR=$(pwd)/tools/bin/MacOSX12.3.sdk IMAGE=$image ./tools/bin/goreleaser_wrapper release --snapshot --clean --config .goreleaser.devspace.yaml
        docker push $image 
hooks:
  - wait:
      running: true
      terminatedWithCode: 0
      timeout: 600
    container:
      labelSelector:
        # vars don't work here, = releaseName
        release: "app"
    events: ["after:deploy:app"]
    name: "wait-for-pod-hook"

# This is a list of `deployments` that DevSpace can create for this project
deployments:
  app:
    namespace: ${DEVSPACE_NAMESPACE}
    helm:
      releaseName: "app"
      chart:
        name: cl-cluster
        path: .
      # for simplicity, we define all the values here
      # they can be defined the same way in values.yml
      # devspace merges these "values" with the "values.yaml" before deploy
      values:
        podSecurityContext:
          fsGroup: 999

        chainlink:
          securityContext:
            capabilities:
              drop:
                - ALL
            readOnlyRootFilesystem: false
            runAsNonRoot: true
            runAsUser: 14933
            runAsGroup: 999
          web_port: 6688
          p2p_port: 6690
          nodes:
            - name: node-1
              image: ${DEVSPACE_IMAGE}
              # default resources are 300m/1Gi
              # first node need more resources to build faster inside container
              # at least 2Gi of memory is required otherwise build will fail (OOM)
              resources:
                requests:
                  cpu: 2000m
                  memory: 2048Mi
                limits:
                  cpu: 2000m
                  memory: 2048Mi
              # override default config per node
              # for example, use OCRv2 P2P setup, the whole config
              #      toml: |
              #        RootDir = './clroot'
              #        [Log]
              #        JSONConsole = true
              #        Level = 'debug'
              #        [WebServer]
              #        AllowOrigins = '*'
              #        SecureCookies = false
              #        SessionTimeout = '999h0m0s'
              #        [OCR2]
              #        Enabled = true
              #        [P2P]
              #        [P2P.V2]
              #        Enabled = false
              #        AnnounceAddresses = []
              #        DefaultBootstrappers = []
              #        DeltaDial = '15s'
              #        DeltaReconcile = '1m0s'
              #        ListenAddresses = []
              #        [[EVM]]
              #        ChainID = '1337'
              #        MinContractPayment = '0'
              #        [[EVM.Nodes]]
              #        Name = 'node-0'
              #        WSURL = 'ws://geth:8546'
              #        HTTPURL = 'http://geth:8544'
              #        [WebServer.TLS]
              #        HTTPSPort = 0
              # or use overridesToml to override some part of configuration
              #      overridesToml: |
            - name: node-2
              image: ${DEVSPACE_IMAGE}
            - name: node-3
              image: ${DEVSPACE_IMAGE}
            - name: node-4
              image: ${DEVSPACE_IMAGE}
            - name: node-5
              image: ${DEVSPACE_IMAGE}
            - name: node-6
              image: ${DEVSPACE_IMAGE}

        # each CL node have a dedicated PostgreSQL 11.15
        # use StatefulSet by setting:
        #
        # stateful: true
        # capacity 10Gi
        #
        # if you are running long tests
        db:
          securityContext:
            capabilities:
              drop:
                - ALL
            readOnlyRootFilesystem: false
            runAsNonRoot: true
            runAsUser: 999
            runAsGroup: 999
          stateful: false
          resources:
            requests:
              cpu: 1
              memory: 1024Mi
            limits:
              cpu: 1
              memory: 1024Mi
        # default cluster shipped with latest Geth ( dev mode by default )
        geth:
          securityContext:
            capabilities:
              drop:
                - ALL
            readOnlyRootFilesystem: false
            runAsNonRoot: true
            runAsUser: 999
            runAsGroup: 999
          version: v1.12.0
          wsrpc-port: 8546
          httprpc-port: 8544
          chains:
            - networkId: 1337
            - networkId: 2337
          blocktime: 1
          resources:
            requests:
              cpu: 1
              memory: 1024Mi
            limits:
              cpu: 1
              memory: 1024Mi
        # mockserver is https://www.mock-server.com/where/kubernetes.html
        # used to stub External Adapters
        mockserver:
          #  image: "mockserver/mockserver"
          #  version: "mockserver-5.15.0"
          securityContext:
            capabilities:
              drop:
                - ALL
            readOnlyRootFilesystem: false
            runAsNonRoot: true
            runAsUser: 999
            runAsGroup: 999
          enabled: true
          releasenameOverride: mockserver
          app:
            runAsUser: 999
            readOnlyRootFilesystem: false
          port: 1080
          resources:
            requests:
              cpu: 1
              memory: 1024Mi
            limits:
              cpu: 1
              memory: 1024Mi
        # monitoring.coreos.com/v1 PodMonitor for each node
        prometheusMonitor: true

        # These ingresses create AWS ALB resources and Route 53 Records.
        ingress:
          enabled: true
          annotation_certificate_arn: ${DEVSPACE_INGRESS_CERT_ARN}
          annotation_group_name: ${DEVSPACE_NAMESPACE}
          hosts:
            - host: ${DEVSPACE_NAMESPACE}-node1.${DEVSPACE_INGRESS_BASE_DOMAIN}
              http:
                paths:
                  - path: /
                    backend:
                      service:
                        name: app-node-1
                        port:
                          number: 6688
            - host: ${DEVSPACE_NAMESPACE}-node2.${DEVSPACE_INGRESS_BASE_DOMAIN}
              http:
                paths:
                  - path: /
                    backend:
                      service:
                        name: app-node-2
                        port:
                          number: 6688
            - host: ${DEVSPACE_NAMESPACE}-node3.${DEVSPACE_INGRESS_BASE_DOMAIN}
              http:
                paths:
                  - path: /
                    backend:
                      service:
                        name: app-node-3
                        port:
                          number: 6688
            - host: ${DEVSPACE_NAMESPACE}-node4.${DEVSPACE_INGRESS_BASE_DOMAIN}
              http:
                paths:
                  - path: /
                    backend:
                      service:
                        name: app-node-4
                        port:
                          number: 6688
            - host: ${DEVSPACE_NAMESPACE}-node5.${DEVSPACE_INGRESS_BASE_DOMAIN}
              http:
                paths:
                  - path: /
                    backend:
                      service:
                        name: app-node-5
                        port:
                          number: 6688
            - host: ${DEVSPACE_NAMESPACE}-node6.${DEVSPACE_INGRESS_BASE_DOMAIN}
              http:
                paths:
                  - path: /
                    backend:
                      service:
                        name: app-node-6
                        port:
                          number: 6688
            - host: ${DEVSPACE_NAMESPACE}-geth-1337-http.${DEVSPACE_INGRESS_BASE_DOMAIN}
              http:
                paths:
                  - path: /
                    backend:
                      service:
                        name: geth-1337
                        port:
                          number: 8544
            - host: ${DEVSPACE_NAMESPACE}-geth-1337-ws.${DEVSPACE_INGRESS_BASE_DOMAIN}
              http:
                paths:
                  - path: /
                    backend:
                      service:
                        name: geth-1337
                        port:
                          number: 8546
            - host: ${DEVSPACE_NAMESPACE}-geth-2337-http.${DEVSPACE_INGRESS_BASE_DOMAIN}
              http:
                paths:
                  - path: /
                    backend:
                      service:
                        name: geth-2337
                        port:
                          number: 8544
            - host: ${DEVSPACE_NAMESPACE}-geth-2337-ws.${DEVSPACE_INGRESS_BASE_DOMAIN}
              http:
                paths:
                  - path: /
                    backend:
                      service:
                        name: geth-2337
                        port:
                          number: 8546
            - host: ${DEVSPACE_NAMESPACE}-mockserver.${DEVSPACE_INGRESS_BASE_DOMAIN}
              http:
                paths:
                  - path: /
                    backend:
                      service:
                        name: mockserver
                        port:
                          number: 1080
        networkPolicyDefault:
          ingress:
            allowCustomCidrs: true
            # Should be a comma separated list of CIDR blocks. To include
            # AWS ALB private CIDRs and optionally other custom CIDRs.
            # Example format: 10.0.0.0/16,192.168.0.1/24
            customCidrs: ${DEVSPACE_INGRESS_CIDRS}
        # deployment placement, standard helm stuff
        podAnnotations:
        nodeSelector:
        tolerations:
        affinity:
